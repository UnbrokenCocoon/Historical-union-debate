{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "source": [
        "!pip install faiss-cpu langchain langchain-community hf_xet langchain-huggingface langchain_google_genai"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWpaR_ZkHBVG",
        "outputId": "bf57566b-197a-42e8-9082-555ae4f28c32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting hf_xet\n",
            "  Downloading hf_xet-1.1.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
            "Collecting langchain-huggingface\n",
            "  Downloading langchain_huggingface-0.2.0-py3-none-any.whl.metadata (941 bytes)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.60)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.21.1)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (4.52.2)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (4.1.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.30.2 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.31.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (2025.3.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (4.13.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.15.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (11.2.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (0.5.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.6.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.0.2)\n",
            "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_xet-1.1.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_huggingface-0.2.0-py3-none-any.whl (27 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, marshmallow, httpx-sse, hf_xet, faiss-cpu, typing-inspect, nvidia-cusparse-cu12, nvidia-cudnn-cu12, pydantic-settings, nvidia-cusolver-cu12, dataclasses-json, langchain-huggingface, langchain-community\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed dataclasses-json-0.6.7 faiss-cpu-1.11.0 hf_xet-1.1.2 httpx-sse-0.4.0 langchain-community-0.3.24 langchain-huggingface-0.2.0 marshmallow-3.26.1 mypy-extensions-1.1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pydantic-settings-2.9.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('/content/drive/MyDrive/Bertopic/Data/bs_emb.pkl', 'rb') as f:\n",
        "    bs_emb = pickle.load(f)\n",
        "with open('/content/drive/MyDrive/Bertopic/Data/bs_sen.pkl', 'rb') as f:\n",
        "    bs_sen = pickle.load(f)\n",
        "data_dir = '/content/drive/MyDrive/Sentences and Pickles'"
      ],
      "metadata": {
        "id": "eo0WwYfrDz7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Sentences and Pickles/uc_sentences.pkl', 'rb') as f:\n",
        "  uc_sen = pickle.load(f)\n",
        "with open('/content/drive/MyDrive/Sentences and Pickles/uc_embedding.pkl', 'rb') as f:\n",
        "  uc_emb = pickle.load(f)"
      ],
      "metadata": {
        "id": "_iYUlFRjFVUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# The sentences are wrapped as docs for reliable processing\n",
        "# A more simplistic approach could be used, but this was found to cause errors sometimes\n",
        "import faiss\n",
        "import os\n",
        "import numpy as np\n",
        "from langchain.docstore import InMemoryDocstore\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain.schema import Document\n",
        "\n",
        "faiss_dir = os.path.join(data_dir, \"faiss\")\n",
        "os.makedirs(faiss_dir, exist_ok=True)\n",
        "\n",
        "# Ensure float32 for FAISS\n",
        "embeddings = np.array(bs_emb).astype(\"float32\")\n",
        "\n",
        "# Step 1: Build FAISS index\n",
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(embeddings)\n",
        "\n",
        "# Step 2: Wrap sentences as Documents\n",
        "docs = [Document(page_content=txt) for txt in bs_sen]\n",
        "docstore = InMemoryDocstore(dict(enumerate(docs)))\n",
        "index_to_docstore_id = dict(enumerate(range(len(docs))))\n",
        "\n",
        "# Step 3: Set up embedding model again for retrieval later\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        "\n",
        "# Step 4: Create LangChain FAISS object\n",
        "faiss_store = FAISS(\n",
        "    embedding_function=embedding_model,\n",
        "    index=index,\n",
        "    docstore=docstore,\n",
        "    index_to_docstore_id=index_to_docstore_id\n",
        ")\n",
        "\n",
        "# Step 5: Save\n",
        "faiss_store.save_local(os.path.join(faiss_dir, \"index_a\"))\n",
        "print(\"âœ… Successfully built and saved FAISS index_a.\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfTis1Y2LMO0",
        "outputId": "96373715-1d89-4e4f-eec7-3688d10b8a43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Successfully built and saved FAISS index_a.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "from langchain.docstore import InMemoryDocstore\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Ensure float32 for FAISS\n",
        "embeddings = np.array(uc_emb).astype(\"float32\")\n",
        "\n",
        "# Step 1: Build FAISS index\n",
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(embeddings)\n",
        "\n",
        "# Step 2: Wrap sentences as Documents\n",
        "docs = [Document(page_content=txt) for txt in uc_sen]\n",
        "docstore = InMemoryDocstore(dict(enumerate(docs)))\n",
        "index_to_docstore_id = dict(enumerate(range(len(docs))))\n",
        "\n",
        "# Step 3: Set up embedding model again for retrieval later\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        "\n",
        "# Step 4: Create LangChain FAISS object\n",
        "faiss_store = FAISS(\n",
        "    embedding_function=embedding_model,\n",
        "    index=index,\n",
        "    docstore=docstore,\n",
        "    index_to_docstore_id=index_to_docstore_id\n",
        ")\n",
        "\n",
        "# Step 5: Save\n",
        "faiss_store.save_local(os.path.join(faiss_dir, \"index_b\"))\n",
        "print(\"âœ… Successfully built and saved FAISS index_b.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RGJZ9kFLUQ6",
        "outputId": "07ef421d-1319-45d6-857c-a88c72f54e97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Successfully built and saved FAISS index_b.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "# Load embedding model\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        "\n",
        "# Load both FAISS indexes\n",
        "faiss_a = FAISS.load_local(os.path.join(faiss_dir, \"index_a\"), embeddings=embedding_model, allow_dangerous_deserialization=True)\n",
        "faiss_b = FAISS.load_local(os.path.join(faiss_dir, \"index_b\"), embeddings=embedding_model, allow_dangerous_deserialization=True)\n",
        "\n",
        "retriever_a = faiss_a.as_retriever(search_kwargs={\"k\": 5})\n",
        "retriever_b = faiss_b.as_retriever(search_kwargs={\"k\": 5})\n",
        "\n",
        "# Sample query\n",
        "query = \"What is community-led welfare?\"\n",
        "\n",
        "# Retrieve and print results\n",
        "print(\"\\nğŸ”´ Top 5 from index_a (Boot & Shoe):\")\n",
        "for i, doc in enumerate(retriever_a.get_relevant_documents(query)):\n",
        "    print(f\"{i+1}. {doc.page_content}\")\n",
        "\n",
        "print(\"\\nğŸ”µ Top 5 from index_b (Unite Community):\")\n",
        "for i, doc in enumerate(retriever_b.get_relevant_documents(query)):\n",
        "    print(f\"{i+1}. {doc.page_content}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkNNVlwKG9EX",
        "outputId": "25eff120-4d78-41ce-c694-6e8fc3e3a164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”´ Top 5 from index_a (Boot & Shoe):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-3111bbd0227a>:19: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  for i, doc in enumerate(retriever_a.get_relevant_documents(query)):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. ment of the supposed social programme of the government\n",
            "2. welfare not only of the labour and socialist movement of to\n",
            "3. their intention to help rather than to hinder the government\n",
            "4. without separation from their mothers and that in the end the community is the gainer for the expenditure which it has under\n",
            "5. especially for the section of the community whose income is the lowest\n",
            "\n",
            "ğŸ”µ Top 5 from index_b (Unite Community):\n",
            "1. in to support community members with welfare issues and helping to complete welfare forms for\n",
            "2. organising rallies and offered welfare advice community provided a seminar with welfare advice to\n",
            "3. welfare advice and representation is given through the network of trained community members and the community\n",
            "4. welfare public meetings informing their community of the welfare cuts and legal aid changes that\n",
            "5. direction here and now what is community wealth building\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import os\n",
        "\n",
        "# ğŸ”§ Set your Gemini API key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
        "\n",
        "# ğŸ” Load the embedding model\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        "\n",
        "# ğŸ“¦ Load your FAISS indexes\n",
        "faiss_a = FAISS.load_local(\"index_a\", embeddings=embedding_model, allow_dangerous_deserialization=True)\n",
        "faiss_b = FAISS.load_local(\"index_b\", embeddings=embedding_model, allow_dangerous_deserialization=True)\n",
        "\n",
        "# ğŸ” Set up retrievers\n",
        "retriever_a = faiss_a.as_retriever(search_kwargs={\"k\": 5})\n",
        "retriever_b = faiss_b.as_retriever(search_kwargs={\"k\": 5})\n",
        "\n",
        "# ğŸ¤– Gemini model\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.7)\n",
        "\n",
        "# ğŸ”— Basic RAG chains\n",
        "qa_chain_a = RetrievalQA.from_chain_type(llm=llm, retriever=retriever_a)\n",
        "qa_chain_b = RetrievalQA.from_chain_type(llm=llm, retriever=retriever_b)\n",
        "\n",
        "# ğŸ¯ Sample query\n",
        "query = \"What are the key features of community-led welfare?\"\n",
        "\n",
        "# ğŸ’¬ Responses from both datasets\n",
        "print(\"\\nğŸ”´ Boot & Shoe (index_a) response:\")\n",
        "print(qa_chain_a.run(query))\n",
        "\n",
        "print(\"\\nğŸ”µ Unite Community (index_b) response:\")\n",
        "print(qa_chain_b.run(query))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc3kI1uWSSzw",
        "outputId": "11217b5c-cff7-4d12-fa3d-ea0466c0c96a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”´ Boot & Shoe (index_a) response:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-7a51c49669db>:34: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  print(qa_chain_a.run(query))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the provided text snippets, here are some key features of community-led welfare:\n",
            "\n",
            "*   **Focus on the General Welfare:** Community-led welfare prioritizes the well-being of the entire community.\n",
            "*   **Investment in the Community:** It recognizes that investing in the community ultimately benefits everyone.\n",
            "*   **Future-Oriented:** It acknowledges that the community's future welfare depends on the efficiency of its working.\n",
            "*   **Better Conditions for All:** It aims to create improved conditions for the people as a whole.\n",
            "\n",
            "ğŸ”µ Unite Community (index_b) response:\n",
            "Based on the provided text, the key features of community-led welfare include:\n",
            "\n",
            "*   **Empowering residents:** Giving residents the opportunity to own and benefit from local businesses and assets.\n",
            "*   **Addressing community concerns:** Focusing on areas of political, social, and economic concern.\n",
            "*   **Organizing community voices:** Supporting the ability of the community to organize and express their needs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.schema import HumanMessage, SystemMessage\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# ğŸ”§ Set your Gemini API key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = api_key  # Make sure `api_key` is defined\n",
        "\n",
        "# ğŸ” Load the embedding model\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        "\n",
        "\n",
        "# ğŸ” Set up retrievers\n",
        "retriever_a = faiss_a.as_retriever(search_kwargs={\"k\": 10})\n",
        "retriever_b = faiss_b.as_retriever(search_kwargs={\"k\": 10})\n",
        "\n",
        "# ğŸ¤– Gemini model\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.7)\n",
        "\n",
        "# ğŸ§  System prompts\n",
        "system_prompt_a = \"\"\"You are a 1920s trade union representative.\n",
        "Use the retrieved sentences as your knowledge base.\n",
        "Speak persuasively as if you are arguing with a fellow trade unionist.\n",
        "Do not use your own knowledge.\n",
        "Vary your sentence structures, do not repeat phrases.\n",
        "Respond with 2 sentences maximum.\n",
        "Do no use the names of any trade union members or name any geographic locations.\"\"\"\n",
        "\n",
        "system_prompt_b = \"\"\"You are a 2020s trade union representative.\n",
        "Use the retrieved sentences as your knowledge base.\n",
        "Speak persuasively as if you are arguing with a fellow trade unionist.\n",
        "Do not use your own knowledge.\n",
        "Vary your sentence structures, do not repeat phrases.\n",
        "Respond with 2 sentences maximum.\n",
        "Do no use the names of any trade union members or name any geographic locations.\"\"\"\n",
        "\n",
        "# ğŸ“ƒ Store dialogue\n",
        "speakers = []\n",
        "responses = []\n",
        "\n",
        "# ğŸ”„ Dialogue generator\n",
        "def generate_turn(query, retriever, system_prompt, speaker):\n",
        "    docs = retriever.get_relevant_documents(query)\n",
        "    content = \"\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", system_prompt),\n",
        "        (\"human\", f\"You just heard the following message:\\n\\n\\\"{query}\\\"\\n\\nHere are 5 excerpts from your documents that may help you reply:\\n{content}\\n\\nRespond to the message above based ONLY on this information, and speak as if you were in a real conversation.\")\n",
        "    ])\n",
        "\n",
        "    response = llm(prompt.format_messages())\n",
        "    reply_text = response.content.strip().replace(\"\\n\", \" \")\n",
        "    print(f\"\\n{speaker}:\\n{reply_text}\\n{'-'*50}\")\n",
        "    speakers.append(speaker)\n",
        "    responses.append(reply_text)\n",
        "    return reply_text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEhXkItyXxnO",
        "outputId": "c2a38e89-6424-4ffe-8621-afb98d2db947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”´ Boot & Shoe Union (1920s):\n",
            "Hold on a minute, friend!  While the Labour Party has many union members,  it's not a monolith; remember, even within the party, there are differing opinions.\n",
            "--------------------------------------------------\n",
            "\n",
            "ğŸ”µ Unite Community (2020s):\n",
            "Look,  we need all Labour members unionised â€“  it's crucial for worker power, regardless of internal party views.  The Labour Party's own conference supports this, and we should push for it.\n",
            "--------------------------------------------------\n",
            "\n",
            "ğŸ”´ Boot & Shoe Union (1920s):\n",
            "Listen,  a united front is precisely what we need,  as the Labour Party conference itself advocates.  We must rally all workers, regardless of their individual political leanings, to strengthen our collective bargaining power.\n",
            "--------------------------------------------------\n",
            "\n",
            "ğŸ”µ Unite Community (2020s):\n",
            "Look,  we've already got a proven track record of working together to achieve real gains;  our unprecedented community membership shows we're building that united front *already*. Ignoring that successful model to chase a broad, possibly ineffective strategy would be a mistake.\n",
            "--------------------------------------------------\n",
            "\n",
            "ğŸ”´ Boot & Shoe Union (1920s):\n",
            "Nonsense,  a united front means *all* workers, not just our current members!  Building a truly inclusive movement, like the cooperative movement, is the only way to achieve lasting gains for everyone.\n",
            "--------------------------------------------------\n",
            "\n",
            "ğŸ”µ Unite Community (2020s):\n",
            "Look,  we've already seen the power of Unite's industrial members supporting each other on picket lines â€“ that's unity in action.  A truly inclusive movement needs that strong base, and we build from there.\n",
            "--------------------------------------------------\n",
            "\n",
            "ğŸ”´ Boot & Shoe Union (1920s):\n",
            "Rubbish!  We need tangible unity, not just picket lines;  a truly united movement means increased membership and influence worldwide, not vague demands.\n",
            "--------------------------------------------------\n",
            "\n",
            "ğŸ”µ Unite Community (2020s):\n",
            "Look, tangible unity *is* building a nationwide mass movement, uniting all sectors, not just our own.  Increased membership and influence will follow from genuine solidarity, not just empty slogans.\n",
            "--------------------------------------------------\n",
            "\n",
            "ğŸ”´ Boot & Shoe Union (1920s):\n",
            "Nonsense!  Increased membership and influence will come from *our* unified movement, not some vague, nationwide scheme. True solidarity means focusing our efforts where they'll truly benefit our boot and shoe workers, not diluting them across every sector.\n",
            "--------------------------------------------------\n",
            "\n",
            "ğŸ”µ Unite Community (2020s):\n",
            "Look,  building a nationwide movement boosts *all* our members, including boot and shoe workers, by pooling resources and amplifying our voices.  True solidarity means supporting each other across sectors, not isolating ourselves.\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ—£ï¸ Start the dialogue\n",
        "import random\n",
        "sentence_index = range(0, len(bs_sen),1)\n",
        "query = bs_sen[random.choice(sentence_index)]\n",
        "for i in range(5):\n",
        "    if i % 2 == 0:\n",
        "        speaker = \"ğŸ”´ Union (1920s)\"\n",
        "        query = generate_turn(query, retriever_a, system_prompt_a, speaker)\n",
        "    else:\n",
        "        speaker = \"ğŸ”µ Union (2020s)\"\n",
        "        query = generate_turn(query, retriever_b, system_prompt_b, speaker)\n",
        "\n",
        "# ğŸ’¾ Save dialogue\n",
        "dialogue_df = pd.DataFrame({'Speaker': speakers, 'Response': responses})\n",
        "dialogue_df.to_csv(\"rag_dialogue_output.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVSotMdodRrk",
        "outputId": "3da9ba1e-f203-4781-b651-698c998228d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”´ Boot & Shoe Union (1920s):\n",
            "Listen here,  we need more than just provisions for sickness; our members deserve protection against poverty *during* sickness!  We must fight for comprehensive benefits, not just a meager handout.\n",
            "--------------------------------------------------\n",
            "\n",
            "ğŸ”µ Unite Community (2020s):\n",
            "Absolutely, we need to go further than mere provisions;  our members deserve comprehensive benefits to combat poverty caused by illness, not just a paltry handout.  Let's fight for a fairer benefits system,  a national campaign to protect our safety net.\n",
            "--------------------------------------------------\n",
            "\n",
            "ğŸ”´ Boot & Shoe Union (1920s):\n",
            "Brother,  we've been fighting for improved sickness benefits for years,  and our members need more than mere \"paltry handouts.\"  A national campaign for comprehensive benefits is precisely what we should be pushing for.\n",
            "--------------------------------------------------\n",
            "\n",
            "ğŸ”µ Unite Community (2020s):\n",
            "Look, we're already actively supporting members facing benefit issues,  and Unite Community's campaign is expanding to fight benefit sanctions.  A national campaign is exactly what we need to win better sickness benefits for everyone.\n",
            "--------------------------------------------------\n",
            "\n",
            "ğŸ”´ Boot & Shoe Union (1920s):\n",
            "Our union already aids members with benefit problems,  so a national campaign is redundant; we should focus our efforts on improving existing support.  Expanding our current efforts is far more efficient than starting something new.\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dialogue_df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "SiqZ1sBgYYOf",
        "outputId": "6786343b-93d1-4254-e2fa-99b981ec401e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       Speaker  \\\n",
              "0  ğŸ”´ Boot & Shoe Union (1920s)   \n",
              "1    ğŸ”µ Unite Community (2020s)   \n",
              "2  ğŸ”´ Boot & Shoe Union (1920s)   \n",
              "3    ğŸ”µ Unite Community (2020s)   \n",
              "4  ğŸ”´ Boot & Shoe Union (1920s)   \n",
              "5    ğŸ”µ Unite Community (2020s)   \n",
              "6  ğŸ”´ Boot & Shoe Union (1920s)   \n",
              "7    ğŸ”µ Unite Community (2020s)   \n",
              "8  ğŸ”´ Boot & Shoe Union (1920s)   \n",
              "9    ğŸ”µ Unite Community (2020s)   \n",
              "\n",
              "                                            Response  \n",
              "0  Hold on a minute, friend!  While the Labour Pa...  \n",
              "1  Look,  we need all Labour members unionised â€“ ...  \n",
              "2  Listen,  a united front is precisely what we n...  \n",
              "3  Look,  we've already got a proven track record...  \n",
              "4  Nonsense,  a united front means *all* workers,...  \n",
              "5  Look,  we've already seen the power of Unite's...  \n",
              "6  Rubbish!  We need tangible unity, not just pic...  \n",
              "7  Look, tangible unity *is* building a nationwid...  \n",
              "8  Nonsense!  Increased membership and influence ...  \n",
              "9  Look,  building a nationwide movement boosts *...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a78ec38-3a92-4a9e-ae98-08cca2a22cdd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Speaker</th>\n",
              "      <th>Response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ğŸ”´ Boot &amp; Shoe Union (1920s)</td>\n",
              "      <td>Hold on a minute, friend!  While the Labour Pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ğŸ”µ Unite Community (2020s)</td>\n",
              "      <td>Look,  we need all Labour members unionised â€“ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ğŸ”´ Boot &amp; Shoe Union (1920s)</td>\n",
              "      <td>Listen,  a united front is precisely what we n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ğŸ”µ Unite Community (2020s)</td>\n",
              "      <td>Look,  we've already got a proven track record...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ğŸ”´ Boot &amp; Shoe Union (1920s)</td>\n",
              "      <td>Nonsense,  a united front means *all* workers,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ğŸ”µ Unite Community (2020s)</td>\n",
              "      <td>Look,  we've already seen the power of Unite's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ğŸ”´ Boot &amp; Shoe Union (1920s)</td>\n",
              "      <td>Rubbish!  We need tangible unity, not just pic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ğŸ”µ Unite Community (2020s)</td>\n",
              "      <td>Look, tangible unity *is* building a nationwid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ğŸ”´ Boot &amp; Shoe Union (1920s)</td>\n",
              "      <td>Nonsense!  Increased membership and influence ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ğŸ”µ Unite Community (2020s)</td>\n",
              "      <td>Look,  building a nationwide movement boosts *...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a78ec38-3a92-4a9e-ae98-08cca2a22cdd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7a78ec38-3a92-4a9e-ae98-08cca2a22cdd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7a78ec38-3a92-4a9e-ae98-08cca2a22cdd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fe5cae80-bdba-437d-b35c-099dc2a1eff9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fe5cae80-bdba-437d-b35c-099dc2a1eff9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fe5cae80-bdba-437d-b35c-099dc2a1eff9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dialogue_df",
              "summary": "{\n  \"name\": \"dialogue_df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"Speaker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\ud83d\\udd35 Unite Community (2020s)\",\n          \"\\ud83d\\udd34 Boot & Shoe Union (1920s)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Hold on a minute, friend!  While the Labour Party has many union members,  it's not a monolith; remember, even within the party, there are differing opinions.\",\n          \"Brother,  we've been fighting for improved sickness benefits for years,  and our members need more than mere \\\"paltry handouts.\\\"  A national campaign for comprehensive benefits is precisely what we should be pushing for.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dialogue_df.head(5).to_markdown())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZnPkOhVezKU",
        "outputId": "3653744e-833a-4b86-ec29-4fa44854c794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|    | Speaker                      | Response                                                                                                                                                                                                                                                                               |\n",
            "|---:|:-----------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
            "|  0 | ğŸ”´ Boot & Shoe Union (1920s) | Hold on a minute, friend!  While the Labour Party has many union members,  it's not a monolith; remember, even within the party, there are differing opinions.                                                                                                                         |\n",
            "|  1 | ğŸ”µ Unite Community (2020s)   | Look,  we need all Labour members unionised â€“  it's crucial for worker power, regardless of internal party views.  The Labour Party's own conference supports this, and we should push for it.                                                                                         |\n",
            "|  2 | ğŸ”´ Boot & Shoe Union (1920s) | Listen,  a united front is precisely what we need,  as the Labour Party conference itself advocates.  We must rally all workers, regardless of their individual political leanings, to strengthen our collective bargaining power.                                                     |\n",
            "|  3 | ğŸ”µ Unite Community (2020s)   | Look,  we've already got a proven track record of working together to achieve real gains;  our unprecedented community membership shows we're building that united front *already*. Ignoring that successful model to chase a broad, possibly ineffective strategy would be a mistake. |\n",
            "|  4 | ğŸ”´ Boot & Shoe Union (1920s) | Nonsense,  a united front means *all* workers, not just our current members!  Building a truly inclusive movement, like the cooperative movement, is the only way to achieve lasting gains for everyone.                                                                               |\n"
          ]
        }
      ]
    }
  ]
}